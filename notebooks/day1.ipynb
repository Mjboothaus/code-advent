{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6559029",
   "metadata": {},
   "source": [
    "## Advent of Code - Day 1\n",
    "\n",
    "- DuckDB SQL version\n",
    "- Python version (initial and enhanced)\n",
    "- Polars version\n",
    "\n",
    "*Note: Space separators led to a few issues with reading the data file.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60ff91c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import polars as pl\n",
    "from collections import Counter\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "169e8fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DAY1_DATA = \"../data/day1_lists.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76076da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77710   11556\n",
      "22632   23674\n",
      "82229   77288\n",
      "35788   30924\n",
      "84000   63702\n"
     ]
    }
   ],
   "source": [
    "# Quick check on the data\n",
    "\n",
    "!head -5 ../data/day1_lists.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fac7b7",
   "metadata": {},
   "source": [
    "## DuckDB SQL method\n",
    "\n",
    "I thought I'd experiment with a SQL-based approach as a bit of a learning / comparison opportunity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed633cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = f\"\"\"\n",
    "WITH data AS (\n",
    "  SELECT \n",
    "    CAST(column0 AS INTEGER) AS L1,\n",
    "    CAST(column1 AS INTEGER) AS L2\n",
    "  FROM read_csv_auto('{DAY1_DATA}', header=false, delim=' ')\n",
    ")\n",
    ", sorted_L1 AS (\n",
    "  SELECT L1, ROW_NUMBER() OVER (ORDER BY L1) AS idx FROM data\n",
    ")\n",
    ", sorted_L2 AS (\n",
    "  SELECT L2, ROW_NUMBER() OVER (ORDER BY L2) AS idx FROM data\n",
    ")\n",
    ", paired_distances AS (\n",
    "  SELECT \n",
    "    sL1.L1,\n",
    "    sL2.L2,\n",
    "    ABS(sL1.L1 - sL2.L2) AS distance\n",
    "  FROM sorted_L1 sL1\n",
    "  JOIN sorted_L2 sL2 ON sL1.idx = sL2.idx\n",
    ")\n",
    ", total_distance AS (\n",
    "  SELECT SUM(distance) AS total_distance FROM paired_distances\n",
    ")\n",
    "SELECT total_distance FROM total_distance;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3aa990d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Distance: 1197984.0\n"
     ]
    }
   ],
   "source": [
    "conn = duckdb.connect()\n",
    "\n",
    "# SQL script to run all steps, creating temp tables for each stage\n",
    "sql_script = f\"\"\"\n",
    "-- Create temporary table with selected columns\n",
    "CREATE TEMPORARY TABLE data AS\n",
    "SELECT \n",
    "  CAST(column0 AS INTEGER) AS L1,\n",
    "  CAST(column3 AS INTEGER) AS L2\n",
    "FROM read_csv_auto('{DAY1_DATA}', header=false, delim=' ');\n",
    "\n",
    "-- Create temporary table with sorted L1\n",
    "CREATE TEMPORARY TABLE sorted_L1 AS\n",
    "SELECT L1, ROW_NUMBER() OVER (ORDER BY L1) AS idx FROM data;\n",
    "\n",
    "-- Create temporary table with sorted L2\n",
    "CREATE TEMPORARY TABLE sorted_L2 AS\n",
    "SELECT L2, ROW_NUMBER() OVER (ORDER BY L2) AS idx FROM data;\n",
    "\n",
    "-- Create temporary table with paired distances\n",
    "CREATE TEMPORARY TABLE paired_distances AS\n",
    "SELECT sL1.L1, sL2.L2, ABS(sL1.L1 - sL2.L2) AS distance\n",
    "FROM sorted_L1 sL1\n",
    "JOIN sorted_L2 sL2 USING (idx);\n",
    "\n",
    "-- Create temporary table with total distance\n",
    "CREATE TEMPORARY TABLE total_distance AS\n",
    "SELECT SUM(distance) AS total_distance FROM paired_distances;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the full pipeline SQL script\n",
    "conn.execute(sql_script)\n",
    "\n",
    "# Fetch and print the final result\n",
    "result = conn.execute(\"SELECT * FROM total_distance\").fetchdf()\n",
    "print(f\"Total Distance: {result.squeeze()}\")\n",
    "\n",
    "# Optional: Fetch and inspect intermediate tables if needed\n",
    "# print(conn.execute(\"SELECT * FROM data LIMIT 5\").fetchdf())\n",
    "# print(conn.execute(\"SELECT * FROM sorted_L1 LIMIT 5\").fetchdf())\n",
    "# print(conn.execute(\"SELECT * FROM paired_distances LIMIT 5\").fetchdf())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540423d4",
   "metadata": {},
   "source": [
    "## Pure Python method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e254cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the lists to a list\n",
    "\n",
    "L1 = []\n",
    "L2 = []\n",
    "with open(DAY1_DATA, \"r\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line:  # Skip empty lines\n",
    "            parts = line.split()  # Splits on whitespace (spaces or tabs)\n",
    "            if len(parts) == 2:\n",
    "                L1.append(int(parts[0]))\n",
    "                L2.append(int(parts[1]))\n",
    "            else:\n",
    "                print(f\"Skipping invalid line: {line}\")\n",
    "\n",
    "# Now l1 and l2 are loaded\n",
    "# For verification, print lengths and first few elements\n",
    "# print(f\"Length of L1: {len(L1)}\")\n",
    "# print(f\"Length of L2: {len(L2)}\")\n",
    "# print(f\"First 5 of L1: {L1[:5]}\")\n",
    "# print(f\"First 5 of L2: {L2[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad42a95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total distance: 1197984\n"
     ]
    }
   ],
   "source": [
    "L1 = sorted(L1)\n",
    "L2 = sorted(L2)\n",
    "diffs = [abs(l1 - l2) for l1, l2 in zip(L1, L2)]\n",
    "total_distance = sum(diffs)\n",
    "print(f\"Total distance: {total_distance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5177404e",
   "metadata": {},
   "source": [
    "Improved version of the initial method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "766be8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total distance: 1197984\n"
     ]
    }
   ],
   "source": [
    "# Read and parse the file in one step using list comprehension\n",
    "with open(DAY1_DATA, \"r\") as f:\n",
    "    data = [line.split() for line in f if line.strip() and len(line.split()) == 2]\n",
    "\n",
    "# Separate the values into two lists and convert to int\n",
    "L1, L2 = zip(*[(int(a), int(b)) for a, b in data])\n",
    "\n",
    "# Convert tuples back to lists (optional, if you need to modify later)\n",
    "L1 = list(L1)\n",
    "L2 = list(L2)\n",
    "\n",
    "# Sort the lists\n",
    "L1.sort()\n",
    "L2.sort()\n",
    "\n",
    "# Calculate sum of absolute differences\n",
    "total_distance = sum(abs(a - b) for a, b in zip(L1, L2))\n",
    "\n",
    "# Debugging output\n",
    "# print(f\"Length of L1: {len(L1)}\")\n",
    "# print(f\"Length of L2: {len(L2)}\")\n",
    "# print(f\"First 5 of L1: {L1[:5]}\")\n",
    "# print(f\"First 5 of L2: {L2[:5]}\")\n",
    "\n",
    "print(f\"Total distance: {total_distance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f1f4cf",
   "metadata": {},
   "source": [
    "## Polars version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77c07b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Distance: 1197984\n"
     ]
    }
   ],
   "source": [
    "# Read the space-separated file with no header\n",
    "df = pl.read_csv(DAY1_DATA, separator=\" \", has_header=False)\n",
    "\n",
    "# Select relevant columns 1 and 4, rename and cast to int\n",
    "df_selected = df.select(\n",
    "    [\n",
    "        pl.col(\"column_1\").cast(pl.Int64).alias(\"L1\"),\n",
    "        pl.col(\"column_4\").cast(pl.Int64).alias(\"L2\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Sort each list separately and add index\n",
    "sorted_L1 = df_selected.select(\"L1\").sort(\"L1\").with_row_index(\"idx\")\n",
    "sorted_L2 = df_selected.select(\"L2\").sort(\"L2\").with_row_index(\"idx\")\n",
    "\n",
    "# Join sorted lists on index to pair elements\n",
    "paired = sorted_L1.join(sorted_L2, on=\"idx\")\n",
    "\n",
    "# Calculate absolute differences and sum them\n",
    "paired = paired.with_columns((pl.col(\"L1\") - pl.col(\"L2\")).abs().alias(\"distance\"))\n",
    "total_distance = paired[\"distance\"].sum()\n",
    "\n",
    "print(\"Total Distance:\", total_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fe7cbc",
   "metadata": {},
   "source": [
    "### --- Part Two ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6191155b",
   "metadata": {},
   "source": [
    "\n",
    "Your analysis only confirmed what everyone feared: the two lists of location IDs are indeed very different.\n",
    "\n",
    "Or are they?\n",
    "\n",
    "The Historians can't agree on which group made the mistakes or how to read most of the Chief's handwriting, but in the commotion you notice an interesting detail: a lot of location IDs appear in both lists! Maybe the other numbers aren't location IDs at all but rather misinterpreted handwriting.\n",
    "\n",
    "This time, you'll need to figure out exactly how often each number from the left list appears in the right list. Calculate a total similarity score by adding up each number in the left list after multiplying it by the number of times that number appears in the right list.\n",
    "\n",
    "Here are the same example lists again:\n",
    "\n",
    "```\n",
    "3   4\n",
    "4   3\n",
    "2   5\n",
    "1   3\n",
    "3   9\n",
    "3   3\n",
    "```\n",
    "\n",
    "For these example lists, here is the process of finding the similarity score:\n",
    "\n",
    "The first number in the left list is 3. It appears in the right list three times, so the similarity score increases by 3 * 3 = 9.\n",
    "The second number in the left list is 4. It appears in the right list once, so the similarity score increases by 4 * 1 = 4.\n",
    "The third number in the left list is 2. It does not appear in the right list, so the similarity score does not increase (2 * 0 = 0).\n",
    "The fourth number, 1, also does not appear in the right list.\n",
    "The fifth number, 3, appears in the right list three times; the similarity score increases by 9.\n",
    "The last number, 3, appears in the right list three times; the similarity score again increases by 9.\n",
    "So, for these example lists, the similarity score at the end of this process is 31 (9 + 4 + 0 + 0 + 9 + 9).\n",
    "\n",
    "Once again consider your left and right lists. What is their similarity score?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d930b6e",
   "metadata": {},
   "source": [
    "```\n",
    "It seems like a slightly odd similarity score as it is taking into account the magnitude of the element (i.e. location ID which is just an arbitrary number?).\n",
    "\n",
    "In any case, for each element in the left list, I need multiply it by its frequency in the right list and then sum these.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad419a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_of_left_in_right(left: List[int], right: List[int]) -> Dict[int, int]:\n",
    "    # Build frequency map for right list\n",
    "    freq_map = Counter(right)\n",
    "    \n",
    "    # Lookup frequencies for left list elements\n",
    "    return {x: freq_map.get(x, 0) for x in left}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e313e332",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_left_right = frequency_of_left_in_right(L1, L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fff79f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_frequency_sum(left: List[int], right: List[int]) -> int:\n",
    "    freq_map = Counter(right)\n",
    "    return sum(val * freq_map.get(val, 0) for val in left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e42cb578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23387399\n"
     ]
    }
   ],
   "source": [
    "result = weighted_frequency_sum(L1, L2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b944c74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad8376d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code-advent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
